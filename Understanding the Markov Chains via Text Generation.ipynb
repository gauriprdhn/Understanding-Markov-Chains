{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Markov Chains??\n",
    "\n",
    "**A Markov Chain is a probabilistic system that provides a way to capture the probability transitions in a system among different states.** \n",
    "* Easier way to say this, consider a simple weather tracking system where we have 2 weather patterns only- \"R\" for Rainy and \"S\" for Sunny. We have a state space of size = 2, which we will refer to as D = {R,S}. A markob chain for this state space will be a mathematical model that will tell us the probability associated with transition from one state to the other. For a 2-state system, we will observe 4 transitions, R >> R, R >> S, S >> R, and S >> S. \n",
    "* Markov chains provide excellent ground for modelling real-world conditions. If independent of the actual phenomena, we would simply assign equal probabilities to each of the transitions. But we know that seldom will a Sunny (S) day be followed by a Rainy (R) only, Sunny weather or any weather pattern tends to prevail for a period before it transitions to the next (lest there be a natural disaster). \n",
    "* We can minic this \"stickyness\" with a two-state Markov chain. When the Markov chain is in state \"R\", it has a 0.9 probability of staying put and a 0.1 chance of leaving for the \"S\" state. Likewise, \"S\" state has 0.9 probability of staying put and a 0.1 chance of transitioning to the \"R\" state.\n",
    "\n",
    "We will study the Markov Chains in context of an NLP problem where we often need to construct text sequences which involve predicting the next word given the current word in the sequence. For simplicity all the transitions will be treated as having equal probability of occurance for a given state. For example, if A is a state that can be followed by B,C,D, or E then each transition, A >> B, A >> C, A >> D or A >> E will have equal chance of occuring.\n",
    "\n",
    "Since, President Trump is yet again being a media hog, I will use the text from his speeches to understand how Markov Chains work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 167635 words.\n"
     ]
    }
   ],
   "source": [
    "def extract_corpus(text_url):\n",
    "    words = []\n",
    "    text = urllib.request.urlopen(text_url)  \n",
    "    for line in text:\n",
    "        line = line.decode('utf-8-sig', errors='ignore')\n",
    "        line = line.strip().lower()\n",
    "        if line not in ['',' ']:\n",
    "            new_words = line.split(' ')\n",
    "            new_words = [word for word in new_words if word not in ['', ' '] and not word.isdigit()]\n",
    "            words += new_words \n",
    "    print('Corpus size: {0} words.'.format(len(words)))\n",
    "    return words\n",
    "\n",
    "corpus = extract_corpus(text_url = 'https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to build the **transition probabilities**. We’ll represent our transitions as a dictionary where the keys are the distinct words in the corpus and the value for a given key is a list of words that appear after that key. To build the chain we just need to iterate through the list of words, add it to the dictionary if it’s not already there, and add the word proceeding it to the list of transition words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain size: 11221 distinct words.\n"
     ]
    }
   ],
   "source": [
    "def transitions_dict(corpus):\n",
    "    hashmap = {}\n",
    "    n_words = len(corpus)\n",
    "    for idx,key in enumerate(corpus):\n",
    "        if n_words > idx + 1:\n",
    "            word = corpus[idx + 1]\n",
    "            if key not in hashmap:\n",
    "                hashmap[key] = [word]\n",
    "            else:\n",
    "                hashmap[key].append(word)\n",
    "    print('Chain size: {0} distinct words.'.format(len(hashmap)))\n",
    "    return hashmap\n",
    "\n",
    "transition_chain = transitions_dict(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though with the above code we are simply adding words to a list for each unique word key in the dictionary, won't it affect the sequence generation later? Answer is Yes, it will impact the generation later but that is desirable because it is simply emulates the phenomena we are trying to observe. If a word occurs multiple times, there’s a higher likelihood that we pick that word proportional to the number of times it appeared after the key relative to all the other words in the corpus that appeared after that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they backed the people that will make our common challenges. for proper instruction from years old, and it’s one company in a real love. and\n"
     ]
    }
   ],
   "source": [
    "def generate_tweet(corpus,transition_chain):\n",
    "    w1 = random.choice(corpus)  \n",
    "    tweet = w1\n",
    "    while len(tweet) < 140:  \n",
    "        w2 = random.choice(transition_chain[w1])\n",
    "        tweet += ' ' + w2\n",
    "        w1 = w2\n",
    "    print(tweet)\n",
    "generate_tweet(corpus,transition_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how each unit is going to work, Let's wrap it up together in one main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 167635 words.\n",
      "Chain size: 11221 distinct words.\n",
      "to south korea. so much — and they’re building an environmental awards from liberty university—do we know we have a company and in business of\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    corpus = extract_corpus(text_url = 'https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt')\n",
    "    transition_chain = transitions_dict(corpus)\n",
    "    generate_tweet(corpus,transition_chain)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an understandable, albeit incoherant response for $1^{st}$ order Markov Chains, let us see how the response changes with $2^{nd}$ order Markov Chains. For this we will modify the transition_dict and generate_tweet functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitions_dict_2nd_order(corpus):\n",
    "    hashmap = {}\n",
    "    n_words = len(corpus)\n",
    "    for idx,key1 in enumerate(corpus):\n",
    "        if n_words > idx + 1 and n_words > idx + 2:\n",
    "            key2, word = corpus[idx + 1], corpus[idx + 2]\n",
    "            if (key1,key2) not in hashmap:\n",
    "                hashmap[(key1,key2)] = [word]\n",
    "            else:\n",
    "                hashmap[(key1,key2)].append(word)\n",
    "    print('Chain size: {0} distinct words.'.format(len(hashmap)))\n",
    "    return hashmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet_2nd_order(corpus,transition_chain,tweet_len=140):\n",
    "    idx = random.randint(0,len(corpus)-1)  \n",
    "    key = (corpus[idx],corpus[idx+1])\n",
    "    tweet = corpus[idx] + ' ' + corpus[idx+1]\n",
    "    \n",
    "    while(len(tweet) < tweet_len):\n",
    "        w = random.choice(transition_chain[key])\n",
    "        tweet += ' ' + w\n",
    "        key = (key[1],w)\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 167635 words.\n",
      "Chain size: 67132 distinct words.\n",
      "\n",
      "\n",
      "– they don’t know. so what did she do? she’s destroyed – i said i’ll never run for president i pledge to protect people. we have to be replaced. i don’t think that our people and hispanics working for\n",
      "\n",
      "\n",
      "to understand that what we want to do this. this is me. look, i always say i’ll be great for the fighter jets. these are the pastors. these are people only believe in each other. here we have to get a\n",
      "\n",
      "\n",
      "$500 billion trade imbalance – $45 to $50 billion. that’s a good job. we’ll get a lot of things. we are really truly signs of strength. although not in all fairness, in all fairness, has lost 15,000 net\n",
      "\n",
      "\n",
      "look at what’s happened, and citizens were attacked, as opposed to it now, they wanted to build our military. just the other papers have turned out to be sued, probably will lose the supreme leader of\n",
      "\n",
      "\n",
      "he doesn’t know what it means. we're going to happen: after i’m called by all of whom are here by the way. i do write about it. how did it take you in all fairness – but have no idea if they happen to\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    corpus = extract_corpus(text_url = 'https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt')\n",
    "    transition_chain = transitions_dict_2nd_order(corpus)\n",
    "    for i in range(5):\n",
    "        print(\"\\n\")\n",
    "        generate_tweet_2nd_order(corpus,transition_chain,tweet_len=200)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
